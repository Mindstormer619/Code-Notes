# Designing Data Intensive Applications - Transactions
> Created: 2023-02-13 20:23

A **transaction** is a way for an application to group several reads and writes together into a logical unit. Conceptually, all the reads and writes in a transaction are executed as one operation: either the entire transaction succeeds (commit) or it fails (abort, rollback). If it fails, the application can safely retry. With transactions, error handling becomes much simpler for an application, because it doesnâ€™t need to worry about partial failureâ€”i.e., the case where some operations succeed and some fail (for whatever reason).

## The Concept of a Transaction

NoSQL databases in general abandon the concept of transactions entirely, or redefine it to mean something much weaker than conventionally accepted, for "scalability" reasons.

While transactions do affect scalability and performance, having transactions does not mean that the database is necessarily slow.

### ACID

**ACID:** Atomicity, Consistency, Isolation, Durability. In practice, DB implementations differ in what they mean by "ACID-compliant", and the term is more marketing-oriented than meaning a strict set of engineering guarantees.

> ðŸ’¡ **BASE:** Basically Available, Soft state, Eventual consistency. Marketing term to oppose ACID, used in NoSQL databases primarily. Terrible and can be used to mean almost anything.

#### Atomicity

Cannot be broken down into further pieces. Generally in multi-threaded applications, atomic operations are ones where one thread cannot see the atomic operation of the other thread in an intermediate state. It sees the state before and after the operation runs. In the context of databases, this is covered by *isolation*.

Atomicity for DBs means that if a client wants to make several writes, but a fault occurs after some writes were processed, then all those writes which have already run are discarded or *rolled back* if the writes were grouped together in a transaction.

In other words, all writes get "locked" in the DB when the transaction *commits*. If the transaction is *aborted*, then the whole thing is rolled back. Atomicity simplifies rerunning the transaction upon encountering failures. *Abortability* might have been a better term.

#### Consistency

In the context of ACID, *consistency* means that the database remains in a "good state" whenever it is observed.

Some forms of consistency can be provided by the DB â€” for instance, foreign key consistency which ensures that DB rows with compulsory foreign keys have valid mappings to the foreign tables. Other forms of consistency have to be guaranteed by the application only â€” for example, in an accounting DB, ensuring that the debits and credits add up.

The conditions that need to be true for consistency are called *invariants*. Consistency is generally an application-specific problem, and it is only included here because "ACID" looks cooler than "AID". This is not a joke.

#### Isolation

*Isolation* in the ACID sense means that concurrently executing transactions are isolated from each other: they cannot step on each others' toes. The classic formalization is *serializability*: even if the transactions actually run concurrently, the net effect should be identical to if they ran serially, i.e. one after the other.

True serializability has a strong performance hit, and most DBs do not actually run in this mode (and some do not support it at all). In practice we use weaker isolation levels most of the time.

#### Durability

*Durability* is the promise that once a transaction commits successfully, any data it has written will not be forgotten, even on hardware faults or system crashes.

In single-node DBs, durability usually means writing to nonvolatile storage (with checksums / RAID replication). In a replicated DB, it may mean that data has been successfully copied over to some number of nodes, and the DB will wait until that many writes are completed before reporting a successful commit.

**Perfect durability does not exist.** If something wipes out all disks and backups at the same time, data is gone. But also, nothing is perfect:
+ On writing to disk, if the machine dies, your data is unavailable until the machine can be restored or the disk moved to another machine.
+ A correlated fault (software bug, power outage) can wipe out all replicas at the same time.
+ In async-replicated systems, writes can be lost on leader failure.
+ SSDs have data loss on power failure, lack of power for longer time, block-based failures.
+ Disks can get corrupted or fail completely.

Various risk reduction techniques need to be used together.

### Single-Object and Multi-Object Operations

**Multi-object transactions** are often needed if several pieces of data need to be kept in sync. For example, you might use a separately maintained unread counter for number of unread emails, which is stored and updated for fast retrieval (to avoid crawling the entire `emails` table and count unread emails each time). Now this is something that needs to be updated in sync every time an email is read.

#### Single-Object writes

Storage engines almost universally provide atomicity and isolation at the level of a single object update (say, one row or one document) on one node. This is to avoid issues where data is partially written, or old and new data are spliced together, or reads see partially written/updated values. Somewhat more complex operations like increments, or compare-and-set, might be available in the context of single-object updates as atomic operations.

#### Why multi-object transactions

+ In relational DBs, a row in one table can have a foreign key to another table, in which case these references need to remain valid by updating entries in both tables at the same time.
+ Document DBs encourage denormalization, which means you might need to update several documents together.
+ In DBs with secondary indices, those indices also need to be updated transactionally along with the data, else data can appear in one index but not in another.

#### Handling errors and aborts

Datastores with leaderless replication usually do not follow full ACID guarantees â€” it runs on a "best effort" basis, the DB will do as much as it can, and if it runs into an error, it won't undo what has already been done. It becomes the application's responsibility to recover from errors.

Retrying aborted transactions can be a simple and effective error handling technique, but isn't perfect:
+ If the transaction actually succeeded, but the acknowledgement was dropped due to a network failure, we might write twice.
+ If the error is due to overload, retrying can make it worse. In this case we should exponentially backoff, or handle overload-related errors differently if possible.
+ It is only worth retrying after transient errors â€” retries after permanent errors (e.g. constraint violation) is pointless.
+ If the transaction has side effects outside the DB, then aborting the transaction might still keep the side effect, which will be re-done on a retry.

## Weak Isolation Levels

Concurrency issues (race conditions) only come into play when two transactions try to modify the same piece of data, or one transaction tries to read a piece of data that's being modified by another.



----

## References
1. DDIA - Chapter 7